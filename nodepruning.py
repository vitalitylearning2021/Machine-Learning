# -*- coding: utf-8 -*-
"""nodePruning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IDSTFxTNO6KOHuNf35npTFiTi5A3op0
"""

import numpy as np

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.initializers import Initializer

# Set a pruning threshold (percentage)
pruning_threshold = 20

# Load the MNIST data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Preprocess the data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Custom initializers
class CustomKernelInitializer(Initializer):
    def __init__(self, weights):
        self.weights = weights

    def __call__(self, shape, dtype=None):
        return self.weights

class CustomBiasInitializer(Initializer):
    def __init__(self, biases):
        self.biases = biases

    def __call__(self, shape, dtype=None):
        return self.biases

def prune_nodes(model, pruning_threshold):

    layers_to_prune = model.layers[:-1]

    # Create a new model with pruned layers
    new_model = Sequential()
    new_model.add(Flatten(input_shape=(28, 28)))

    for i, layer in enumerate(layers_to_prune):
        if isinstance(layer, Dense):
            weights, biases = layer.get_weights()

            if i > 1:
              weights = weights[~old_nodes_to_prune, :]

            # Calculate the sum of input weights to each node
            sum_input_weights = np.sum(np.abs(weights) / np.max(np.abs(weights)), axis=0)

            next_layer_weights, _ = model.layers[i + 1].get_weights()
            sum_output_weights    = np.sum(np.abs(next_layer_weights) / np.max(np.abs(next_layer_weights)), axis=1)

            # Total sum of weights for each node
            total_weights_sum = sum_input_weights + sum_output_weights

            # Determine nodes to prune based on the total sum of weights
            threshold = np.percentile(total_weights_sum, pruning_threshold)
            nodes_to_prune = total_weights_sum  < threshold

            # Prune the weights and biases
            pruned_weights  = weights[:, ~nodes_to_prune]
            pruned_biases   = biases[~nodes_to_prune]

            # Initialize the custom initializers
            kernel_initializer = CustomKernelInitializer(pruned_weights)
            bias_initializer = CustomBiasInitializer(pruned_biases)

            new_model.add(Dense(pruned_weights.shape[1], kernel_initializer = kernel_initializer, bias_initializer = bias_initializer, activation = 'relu'))

            old_nodes_to_prune = nodes_to_prune

    # Get weights and biases of the last layer
    weights, biases = model.layers[-1].get_weights()

    # Prune the weights and biases
    weights  = weights[~nodes_to_prune, :]

    # Initialize the custom initializers
    kernel_initializer = CustomKernelInitializer(weights)
    bias_initializer = CustomBiasInitializer(biases)

    new_model.add(Dense(10, kernel_initializer = kernel_initializer, bias_initializer = bias_initializer, activation='softmax'))

    return new_model

# Build a simple neural network model
original_model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

# Compile the model
original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
original_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

print(original_model.summary())

# Evaluate the origina model
loss, accuracy = original_model.evaluate(x_test, y_test)
print(f'Test accuracy before pruning: {accuracy}')

# Prune the nodes in the model and get the new pruned model
pruned_model = prune_nodes(original_model, pruning_threshold)

print(pruned_model.summary())

# Compile the pruned model
pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Retrain the pruned model
pruned_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# Evaluate the pruned model
loss, accuracy = pruned_model.evaluate(x_test, y_test)
print(f'Test accuracy after pruning: {accuracy}')